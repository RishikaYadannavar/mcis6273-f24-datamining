{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3cbadb-0fe9-4b35-b164-1439ce47d90b",
   "metadata": {},
   "source": [
    "# ABOUT DATA MINING (using headings one level )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265932b-1142-4930-bd29-a9f5f65c8b34",
   "metadata": {},
   "source": [
    "##### (using paragraph)\n",
    "Data mining is the process of discovering patterns, correlations, trends, and useful information from large sets of data, using a combination of statistical analysis, machine learning, and database systems. \n",
    "The goal of data mining is to extract knowledge from a data set and transform it into an understandable structure for further use. (using paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89327ef-22ca-4a49-b142-805866359e9e",
   "metadata": {},
   "source": [
    "##### (using bullets)\n",
    "##### Here are key points to understand about data mining:\n",
    "* Pattern Discovery\n",
    "* Predictive Analysis\n",
    "* Large Datasets\n",
    "* Diverse Applications\n",
    "* Techniques and Tools\n",
    "* Ethical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f641fcd-3a1f-40ee-b3fc-1c84d08e735c",
   "metadata": {},
   "source": [
    "#### (using bold)\n",
    "**Pattern Discovery**: It involves identifying unusual patterns or anomalies and consistent patterns in data. For example, finding frequent buying patterns in supermarket transaction data.\n",
    "\n",
    "**Predictive Analysis**: Data mining can be used to construct models that predict future trends or behaviors. \n",
    "\n",
    "**Large Datasets**: Data mining is particularly useful for dealing with large quantities of data (Big Data), where manual analysis would be impractical or impossible.\n",
    "\n",
    "**Diverse Applications**: It is used across a wide range of industries, such as finance for credit scoring and fraud detection, marketing for customer segmentation, retail for inventory management, and in healthcare for predicting patient outcomes.\n",
    "\n",
    "**Techniques and Tools**: Data mining employs a variety of techniques including clustering (finding groups of similar items), classification (assigning items to predefined categories), regression (predicting a continuous value), and association rule learning (discovering relationships between variables).\n",
    "\n",
    "**Ethical Considerations**: With its ability to uncover patterns and personal information, data mining raises privacy and ethical concerns. It's important to use data mining techniques responsibly and in compliance with privacy laws and ethical standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02423bfd-da64-46c5-9d30-08481d042be9",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc605407-e8ba-492f-8e3a-833e8f142451",
   "metadata": {},
   "source": [
    "#### (using italics)\n",
    "*In summary, data mining is a powerful tool that allows organizations to make informed decisions by identifying trends, patterns, and relationships in data that might not be immediately apparent. Its applications are vast and can provide significant competitive advantages and insights for businesses and researchers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa93a22-61c4-400a-adf8-2dcb63c7151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'resultset': {'offset': 1, 'count': 11, 'limit': 25}}, 'results': [{'uid': 'gov.noaa.ncdc:C00861', 'mindate': '1750-02-01', 'maxdate': '2024-01-28', 'name': 'Daily Summaries', 'datacoverage': 1, 'id': 'GHCND'}, {'uid': 'gov.noaa.ncdc:C00946', 'mindate': '1763-01-01', 'maxdate': '2024-01-01', 'name': 'Global Summary of the Month', 'datacoverage': 1, 'id': 'GSOM'}, {'uid': 'gov.noaa.ncdc:C00947', 'mindate': '1763-01-01', 'maxdate': '2024-01-01', 'name': 'Global Summary of the Year', 'datacoverage': 1, 'id': 'GSOY'}, {'uid': 'gov.noaa.ncdc:C00345', 'mindate': '1991-06-05', 'maxdate': '2024-01-29', 'name': 'Weather Radar (Level II)', 'datacoverage': 0.95, 'id': 'NEXRAD2'}, {'uid': 'gov.noaa.ncdc:C00708', 'mindate': '1994-05-20', 'maxdate': '2024-01-27', 'name': 'Weather Radar (Level III)', 'datacoverage': 0.95, 'id': 'NEXRAD3'}, {'uid': 'gov.noaa.ncdc:C00821', 'mindate': '2010-01-01', 'maxdate': '2010-01-01', 'name': 'Normals Annual/Seasonal', 'datacoverage': 1, 'id': 'NORMAL_ANN'}, {'uid': 'gov.noaa.ncdc:C00823', 'mindate': '2010-01-01', 'maxdate': '2010-12-31', 'name': 'Normals Daily', 'datacoverage': 1, 'id': 'NORMAL_DLY'}, {'uid': 'gov.noaa.ncdc:C00824', 'mindate': '2010-01-01', 'maxdate': '2010-12-31', 'name': 'Normals Hourly', 'datacoverage': 1, 'id': 'NORMAL_HLY'}, {'uid': 'gov.noaa.ncdc:C00822', 'mindate': '2010-01-01', 'maxdate': '2010-12-01', 'name': 'Normals Monthly', 'datacoverage': 1, 'id': 'NORMAL_MLY'}, {'uid': 'gov.noaa.ncdc:C00505', 'mindate': '1970-05-12', 'maxdate': '2014-01-01', 'name': 'Precipitation 15 Minute', 'datacoverage': 0.25, 'id': 'PRECIP_15'}, {'uid': 'gov.noaa.ncdc:C00313', 'mindate': '1900-01-01', 'maxdate': '2014-01-01', 'name': 'Precipitation Hourly', 'datacoverage': 1, 'id': 'PRECIP_HLY'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_data_from_url(url, token):\n",
    "    # Set up the headers with the web token for authentication\n",
    "    headers = {\n",
    "        'Token': f'{token}',\n",
    "        'Email': 'RYadannavar4686@muleriders.saumag.edu'\n",
    "\n",
    "    }\n",
    "\n",
    "    # Make the HTTP GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Process the data (assuming it's JSON)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        # Handle errors (e.g., print an error message)\n",
    "        print(f'Failed to fetch data: {response.status_code}')\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = 'https://www.ncei.noaa.gov/cdo-web/api/v2/datasets/'  # Replace with the actual URL\n",
    "token = 'SewXCENnyBLmAxmyRLWgIvmDiuxbmHbh'         # Replace with your actual web token\n",
    "data = get_data_from_url(url, token)\n",
    "\n",
    "if data is not None:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114b36d-5d6f-4a17-be77-b7fc46f81307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2008 saved to data/winter_2008-2009.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to fetch data from NOAA for a given range\n",
    "def fetch_noaa_data(start_date, end_date, token):\n",
    "    base_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n",
    "    params = {\n",
    "        'datasetid': 'GHCND',\n",
    "        'locationid': 'ZIP:80249',\n",
    "        'units': 'standard',\n",
    "        'startdate': start_date,\n",
    "        'enddate': end_date,\n",
    "        'limit': 1000\n",
    "    }\n",
    "    headers = {\n",
    "        'token': token\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Directory to save JSON files\n",
    "data_dir = 'data/'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Your API token\n",
    "api_token = 'SewXCENnyBLmAxmyRLWgIvmDiuxbmHbh'\n",
    "\n",
    "# Loop through the years 2008-2022\n",
    "for year in range(2008, 2023):\n",
    "    # Construct the start and end dates for the API call\n",
    "    start_date = f'{year}-12-15'\n",
    "    end_date = f'{year+1}-01-21'\n",
    "    \n",
    "    # Fetch the data\n",
    "    data = fetch_noaa_data(start_date, end_date, api_token)\n",
    "    \n",
    "    # Save the data to a JSON file\n",
    "    file_path = os.path.join(data_dir, f'winter_{year}-{year+1}.json')\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    print(f'Data for {year} saved to {file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d675b34f-fea2-448f-bde5-d5717adcab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to data/all_data_max_min_avg.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_632/1518970275.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize a DataFrame to store the aggregated data\n",
    "aggregated_data = pd.DataFrame()\n",
    "\n",
    "# Directory containing the JSON files\n",
    "data_dir = 'data/'\n",
    "\n",
    "# Process each JSON file and calculate the TAVG\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.startswith('winter_') and file_name.endswith('.json'):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            # Create a DataFrame from the current JSON file's data\n",
    "            df = pd.DataFrame(data['results'])\n",
    "            \n",
    "            # Filter out records that don't have TMAX or TMIN as their datatype\n",
    "            df_tmax = df[df['datatype'] == 'TMAX'].rename(columns={'value': 'TMAX'}).drop('datatype', axis=1)\n",
    "            df_tmin = df[df['datatype'] == 'TMIN'].rename(columns={'value': 'TMIN'}).drop('datatype', axis=1)\n",
    "            \n",
    "            # Merge the TMAX and TMIN data on the date field\n",
    "            df_merged = pd.merge(df_tmax, df_tmin, on='date')\n",
    "            \n",
    "            # Calculate TAVG\n",
    "            df_merged['TAVG'] = (df_merged['TMAX'] + df_merged['TMIN']) / 2\n",
    "            \n",
    "            # Append the processed data to the aggregated DataFrame\n",
    "            aggregated_data = pd.concat([aggregated_data, df_merged])\n",
    "\n",
    "# Set the date as the index\n",
    "aggregated_data['date'] = pd.to_datetime(aggregated_data['date'])\n",
    "aggregated_data.set_index('date', inplace=True)\n",
    "\n",
    "# Sort by date\n",
    "aggregated_data.sort_index(inplace=True)\n",
    "\n",
    "# Select only the required columns\n",
    "aggregated_data = aggregated_data[['TMAX', 'TMIN', 'TAVG']]\n",
    "\n",
    "# Save to CSV\n",
    "csv_file_path = os.path.join(data_dir, 'all_data_max_min_avg.csv')\n",
    "aggregated_data.to_csv(csv_file_path)\n",
    "\n",
    "print(f'CSV file saved to {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97906eb7-77a2-4b86-abe6-7926dca5a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Directory containing the JSON files\n",
    "data_dir = 'data/'  # Modify this to your local data directory\n",
    "\n",
    "# Initialize a DataFrame to store the compiled data\n",
    "compiled_data = pd.DataFrame()\n",
    "\n",
    "# Loop over each year and process the corresponding JSON file\n",
    "for year in range(2008, 2023):\n",
    "    year_range = f'{year}-{year+1}'\n",
    "    json_file = f'winter_{year_range}.json'\n",
    "    json_path = os.path.join(data_dir, json_file)\n",
    "\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as file:\n",
    "            data = json.load(file)['results']\n",
    "            \n",
    "            # Temporary storage for TMAX and TMIN values\n",
    "            tmax_values = {}\n",
    "            tmin_values = {}\n",
    "\n",
    "            # Extract and process TAVG for each date\n",
    "            for record in data:\n",
    "                \n",
    "                date_str = datetime.strptime(record['date'], '%Y-%m-%dT%H:%M:%S').strftime('%m-%d')\n",
    "                if record['datatype'] == 'TMAX':\n",
    "                    tmax_values[date_str] = record['value']\n",
    "                elif record['datatype'] == 'TMIN':\n",
    "                    tmin_values[date_str] = record['value']\n",
    "\n",
    "            # Calculate TAVG for each date\n",
    "            for date_str in tmax_values:\n",
    "                if date_str in tmin_values:\n",
    "                    tavg = (tmax_values[date_str] + tmin_values[date_str]) / 2\n",
    "                    # print(tavg,date_str, year_range )\n",
    "                    compiled_data.at[date_str, year_range] = tavg\n",
    "            #print(compiled_data)\n",
    "#Save the compiled data to a CSV file\n",
    "csv_file_path = os.path.join(data_dir, 'all_data_min.csv')\n",
    "compiled_data.to_csv(csv_file_path, index=True)\n",
    "\n",
    "print(f\"CSV file saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e842a7e5-17e7-4a18-bd9d-47d017e842cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_data=pd.read_csv('all_data_min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc316c4-5623-409a-9c11-c9b7ad4688c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2008-2009</th>\n",
       "      <th>2009-2010</th>\n",
       "      <th>2010-2011</th>\n",
       "      <th>2011-2012</th>\n",
       "      <th>2012-2013</th>\n",
       "      <th>2013-2014</th>\n",
       "      <th>2014-2015</th>\n",
       "      <th>2015-2016</th>\n",
       "      <th>2016-2017</th>\n",
       "      <th>2017-2018</th>\n",
       "      <th>2018-2019</th>\n",
       "      <th>2019-2020</th>\n",
       "      <th>2020-2021</th>\n",
       "      <th>2021-2022</th>\n",
       "      <th>2022-2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-15</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-17</td>\n",
       "      <td>25.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-18</td>\n",
       "      <td>16.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-19</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  2008-2009  2009-2010  2010-2011  2011-2012  2012-2013  \\\n",
       "0      12-15       -8.5       37.5       38.5       30.0       36.0   \n",
       "1      12-16       13.0       42.5       26.0       27.0       32.0   \n",
       "2      12-17       25.5       38.5       24.5       29.0       36.5   \n",
       "3      12-18       16.5       30.0       25.5       41.5       33.5   \n",
       "4      12-19       29.0       32.5       38.0       29.5       15.5   \n",
       "\n",
       "   2013-2014  2014-2015  2015-2016  2016-2017  2017-2018  2018-2019  \\\n",
       "0        NaN       30.0       18.5       34.5       42.5       41.5   \n",
       "1        NaN       23.0       19.5       27.0       39.5       42.5   \n",
       "2        NaN       29.5       10.0       -6.0       31.5       42.5   \n",
       "3        NaN       33.0       29.5        3.5       37.0       41.0   \n",
       "4        NaN       34.0       38.0       23.5       38.0       39.0   \n",
       "\n",
       "   2019-2020  2020-2021  2021-2022  2022-2023  \n",
       "0       24.0       20.0       36.5       17.5  \n",
       "1       24.0       29.0       34.0       15.0  \n",
       "2       28.5       34.0       27.5       16.0  \n",
       "3       42.0       28.0       24.5       26.5  \n",
       "4       32.0       30.0       44.0       30.5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36b69e9-ea88-4aee-abed-35749d3ab173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "2008-2009      0\n",
       "2009-2010      0\n",
       "2010-2011      0\n",
       "2011-2012      0\n",
       "2012-2013      0\n",
       "2013-2014     16\n",
       "2014-2015      0\n",
       "2015-2016      0\n",
       "2016-2017      0\n",
       "2017-2018      0\n",
       "2018-2019      0\n",
       "2019-2020      0\n",
       "2020-2021      0\n",
       "2021-2022      0\n",
       "2022-2023      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67479b3-eb31-4ee7-acf6-1de6b7310e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "denver_data=airport_data.drop('2013-2014', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29adcb7-a3f7-43bf-a69f-8b0b7ebd9168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2008-2009</th>\n",
       "      <th>2009-2010</th>\n",
       "      <th>2010-2011</th>\n",
       "      <th>2011-2012</th>\n",
       "      <th>2012-2013</th>\n",
       "      <th>2014-2015</th>\n",
       "      <th>2015-2016</th>\n",
       "      <th>2016-2017</th>\n",
       "      <th>2017-2018</th>\n",
       "      <th>2018-2019</th>\n",
       "      <th>2019-2020</th>\n",
       "      <th>2020-2021</th>\n",
       "      <th>2021-2022</th>\n",
       "      <th>2022-2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-15</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-17</td>\n",
       "      <td>25.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-18</td>\n",
       "      <td>16.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-19</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  2008-2009  2009-2010  2010-2011  2011-2012  2012-2013  \\\n",
       "0      12-15       -8.5       37.5       38.5       30.0       36.0   \n",
       "1      12-16       13.0       42.5       26.0       27.0       32.0   \n",
       "2      12-17       25.5       38.5       24.5       29.0       36.5   \n",
       "3      12-18       16.5       30.0       25.5       41.5       33.5   \n",
       "4      12-19       29.0       32.5       38.0       29.5       15.5   \n",
       "\n",
       "   2014-2015  2015-2016  2016-2017  2017-2018  2018-2019  2019-2020  \\\n",
       "0       30.0       18.5       34.5       42.5       41.5       24.0   \n",
       "1       23.0       19.5       27.0       39.5       42.5       24.0   \n",
       "2       29.5       10.0       -6.0       31.5       42.5       28.5   \n",
       "3       33.0       29.5        3.5       37.0       41.0       42.0   \n",
       "4       34.0       38.0       23.5       38.0       39.0       32.0   \n",
       "\n",
       "   2020-2021  2021-2022  2022-2023  \n",
       "0       20.0       36.5       17.5  \n",
       "1       29.0       34.0       15.0  \n",
       "2       34.0       27.5       16.0  \n",
       "3       28.0       24.5       26.5  \n",
       "4       30.0       44.0       30.5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646848a9-790a-401d-a89c-379ecb5afa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2008-2009</th>\n",
       "      <th>2009-2010</th>\n",
       "      <th>2010-2011</th>\n",
       "      <th>2011-2012</th>\n",
       "      <th>2012-2013</th>\n",
       "      <th>2014-2015</th>\n",
       "      <th>2015-2016</th>\n",
       "      <th>2016-2017</th>\n",
       "      <th>2017-2018</th>\n",
       "      <th>2018-2019</th>\n",
       "      <th>2019-2020</th>\n",
       "      <th>2020-2021</th>\n",
       "      <th>2021-2022</th>\n",
       "      <th>2022-2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>01-17</td>\n",
       "      <td>40.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>01-18</td>\n",
       "      <td>46.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01-19</td>\n",
       "      <td>48.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>01-20</td>\n",
       "      <td>48.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>01-21</td>\n",
       "      <td>56.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  2008-2009  2009-2010  2010-2011  2011-2012  2012-2013  \\\n",
       "33      01-17       40.5       41.5       47.5       15.5       34.5   \n",
       "34      01-18       46.5       40.5       39.0       30.0       44.0   \n",
       "35      01-19       48.5       34.5       26.5       46.5       41.0   \n",
       "36      01-20       48.5       29.0       22.5       43.0       30.5   \n",
       "37      01-21       56.0       31.5       34.5       48.0       36.5   \n",
       "\n",
       "    2014-2015  2015-2016  2016-2017  2017-2018  2018-2019  2019-2020  \\\n",
       "33       44.5       25.0       31.5       33.0       43.0       37.0   \n",
       "34       50.0       36.5       36.5       46.5       32.0       28.5   \n",
       "35       44.5       33.0       38.0       51.0       35.0       28.5   \n",
       "36       34.5       37.0       35.5       37.5       44.0       35.0   \n",
       "37       23.0       30.5       30.5       25.5       40.0       41.0   \n",
       "\n",
       "    2020-2021  2021-2022  2022-2023  \n",
       "33       38.0       43.0       29.5  \n",
       "34       30.5       41.0       22.0  \n",
       "35       30.5       24.0       20.0  \n",
       "36       40.5       27.5       19.5  \n",
       "37       37.5       26.0       21.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denver_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2805369-3ab7-4a85-ae26-d81b3df95fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "2008-2009     0\n",
       "2009-2010     0\n",
       "2010-2011     0\n",
       "2011-2012     0\n",
       "2012-2013     0\n",
       "2014-2015     0\n",
       "2015-2016     0\n",
       "2016-2017     0\n",
       "2017-2018     0\n",
       "2018-2019     0\n",
       "2019-2020     0\n",
       "2020-2021     0\n",
       "2021-2022     0\n",
       "2022-2023     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denver_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f51e08a-1bc8-4d04-b8d4-0b24dee8ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  38 non-null     object \n",
      " 1   2008-2009   38 non-null     float64\n",
      " 2   2009-2010   38 non-null     float64\n",
      " 3   2010-2011   38 non-null     float64\n",
      " 4   2011-2012   38 non-null     float64\n",
      " 5   2012-2013   38 non-null     float64\n",
      " 6   2014-2015   38 non-null     float64\n",
      " 7   2015-2016   38 non-null     float64\n",
      " 8   2016-2017   38 non-null     float64\n",
      " 9   2017-2018   38 non-null     float64\n",
      " 10  2018-2019   38 non-null     float64\n",
      " 11  2019-2020   38 non-null     float64\n",
      " 12  2020-2021   38 non-null     float64\n",
      " 13  2021-2022   38 non-null     float64\n",
      " 14  2022-2023   38 non-null     float64\n",
      "dtypes: float64(14), object(1)\n",
      "memory usage: 4.6+ KB\n"
     ]
    }
   ],
   "source": [
    "denver_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc1f646a-821c-4207-8525-5bf8d1369c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denver_data.rename(columns={'Unnamed: 0': 'Date'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "677f3802-7919-4511-ba85-b27fd0e6bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>2008-2009</th>\n",
       "      <th>2009-2010</th>\n",
       "      <th>2010-2011</th>\n",
       "      <th>2011-2012</th>\n",
       "      <th>2012-2013</th>\n",
       "      <th>2014-2015</th>\n",
       "      <th>2015-2016</th>\n",
       "      <th>2016-2017</th>\n",
       "      <th>2017-2018</th>\n",
       "      <th>2018-2019</th>\n",
       "      <th>2019-2020</th>\n",
       "      <th>2020-2021</th>\n",
       "      <th>2021-2022</th>\n",
       "      <th>2022-2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-15</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-17</td>\n",
       "      <td>25.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-18</td>\n",
       "      <td>16.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-19</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Date  2008-2009  2009-2010  2010-2011  2011-2012  2012-2013  2014-2015  \\\n",
       "0  12-15       -8.5       37.5       38.5       30.0       36.0       30.0   \n",
       "1  12-16       13.0       42.5       26.0       27.0       32.0       23.0   \n",
       "2  12-17       25.5       38.5       24.5       29.0       36.5       29.5   \n",
       "3  12-18       16.5       30.0       25.5       41.5       33.5       33.0   \n",
       "4  12-19       29.0       32.5       38.0       29.5       15.5       34.0   \n",
       "\n",
       "   2015-2016  2016-2017  2017-2018  2018-2019  2019-2020  2020-2021  \\\n",
       "0       18.5       34.5       42.5       41.5       24.0       20.0   \n",
       "1       19.5       27.0       39.5       42.5       24.0       29.0   \n",
       "2       10.0       -6.0       31.5       42.5       28.5       34.0   \n",
       "3       29.5        3.5       37.0       41.0       42.0       28.0   \n",
       "4       38.0       23.5       38.0       39.0       32.0       30.0   \n",
       "\n",
       "   2021-2022  2022-2023  \n",
       "0       36.5       17.5  \n",
       "1       34.0       15.0  \n",
       "2       27.5       16.0  \n",
       "3       24.5       26.5  \n",
       "4       44.0       30.5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170212be-03c6-4a73-8d56-12b86f6a6444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal average of the warmest(maximum) temperatures: 48.5\n",
      "Seasonal average of the coldest temperatures(minimum): 2.5\n",
      "Overall average temperature(average): 30.29887218045113\n"
     ]
    }
   ],
   "source": [
    "def average_warmest(df):\n",
    "    max_data = df.drop(columns=['Date']).max()\n",
    "    seasonal_max_avg = max_data.mean()\n",
    "    return seasonal_max_avg\n",
    "\n",
    "def average_coldest(df):\n",
    "    min_data = df.drop(columns=['Date']).min()\n",
    "    seasonal_min_avg = min_data.mean()\n",
    "    return seasonal_min_avg\n",
    "    \n",
    "def average(df):\n",
    "    avg_data = df.drop(columns=['Date']).mean().mean()\n",
    "    return avg_data\n",
    "\n",
    "avg_warmest = average_warmest(denver_data)\n",
    "avg_coldest = average_coldest(denver_data)\n",
    "avg_overall = average(denver_data)\n",
    "\n",
    "print(f\"Seasonal average of the warmest(maximum) temperatures: {avg_warmest}\")\n",
    "print(f\"Seasonal average of the coldest temperatures(minimum): {avg_coldest}\")\n",
    "print(f\"Overall average temperature(average): {avg_overall}\")\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e2cfb0-9924-4e46-b4fa-f0811581a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.19.5\n",
      "Uninstalling numpy-1.19.5:\n",
      "  Successfully uninstalled numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928d0d54-a025-415b-8b17-957b234d5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.24.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "662d7147-2bd0-4fdb-ad95-cd9441dac597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/envs/sau24s/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (2023.11.17)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b39b048-f79c-4c89-af61-80c4f2be31f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from seaborn) (1.24.4)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Using cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Using cached matplotlib-3.7.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached fonttools-4.47.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (157 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Collecting tzdata>=2022.1 (from pandas>=1.2->seaborn)\n",
      "  Using cached tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/sau24s/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached matplotlib-3.7.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "Using cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Using cached contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached fonttools-4.47.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, fonttools, contourpy, pandas, matplotlib, seaborn\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.5\n",
      "    Uninstalling pandas-1.0.5:\n",
      "      Successfully uninstalled pandas-1.0.5\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.2\n",
      "    Uninstalling matplotlib-3.3.2:\n",
      "      Successfully uninstalled matplotlib-3.3.2\n",
      "Successfully installed contourpy-1.1.1 fonttools-4.47.2 matplotlib-3.7.4 pandas-2.0.3 seaborn-0.13.2 tzdata-2023.4\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00490f27-4793-4dd0-8a4a-ba188016308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62d42a44-6905-4d4f-be92-80efd6e66c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(denver_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1c402-db63-4d0a-8e41-c60534a5caa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sau24s]",
   "language": "python",
   "name": "conda-env-sau24s-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
